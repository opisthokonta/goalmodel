% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/goalmodel_misc.R
\name{score_predictions}
\alias{score_predictions}
\title{Scoring rules to evaluate prediction accuracy}
\usage{
score_predictions(predictions, observed, score)
}
\arguments{
\item{predictions}{A matrix or data frame with probabilities, with one column for each outcome, and one row for each prediction.}

\item{observed}{Numeric or character vector of the same length as the number of predictions. It must contain an indicator of the observed outcome,
either a column number or a column name.}

\item{score}{Character vector of the scoring functions to use. Currently 'log', 'brier', and 'rps' are available.}
}
\description{
This function provides scoring rules for evaluating prediction accuracy.
}
\details{
Currently three scoring rules are available: The log score, Brier score, and
the Ranked Probability Score (RPS).

The log score is just the negative logarithm of the probability of the observed outcome.

For all three scoring functions, a lower score means a better predictions. They will attain a
lowest possible score of 0 if the observed outcome were predicted with a 100% probability.'
The RPS has an upper limit of 1, which indicates the worst possible
prediction. The Brier score has an upper limit of 2. The log score has no upper
limit, and will be infinite if the observed outcome were predicted with probability 0.
}
\references{
Wheatcroft, E. (2021) Evaluating probabilistic forecasts of football matches: the case against the ranked probability score.
https://doi.org/10.1515/jqas-2019-0089

Constantinou, A. C., and N. E. Fenton (2012) Solving the Problem of Inadequate Scoring Rules for Assessing Probabilistic Football Forecast Models. https://doi.org/10.1515/1559-0410.1418
}
